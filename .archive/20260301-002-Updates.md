# Pending Updates (2026-03-01) — Batch 002

**Date:** 2026-03-01
**Scope:** shruggie-indexer
**Status:** PENDING
**Supersedes:** `20260301-001-Updates.md`

---

## Overview

This batch introduces two user-facing feature enhancements: provenance-preserving de-duplication during rename operations, and the ability to suppress directory metadata output files. Both features address real-world usage friction identified through repeated manual post-processing of indexer output.

**Revision notes (002):** This edition replaces the 001 draft entirely. Section 1 is redesigned from the ground up — the original destructive "delete-and-discard" approach is replaced with a provenance-preserving architecture that captures complete duplicate identity metadata via a new `duplicates` schema field. Section 2 is corrected to enforce proper Unix-like stdout orthogonality and to resolve the Single-file-mode output contradiction. A new Section 4 documents required amendments to the archived ecosystem direction document.

### Session Ordering

1. **Section 1** (Provenance-Preserving De-Duplication) — New `duplicates` schema field, new `core/dedup.py` module, pipeline integration, schema changes. Largest section.
2. **Section 2** (Suppress Directory Metadata Output) — New config field, CLI flag, GUI checkbox. Corrected stdout orthogonality.
3. **Section 3** (Specification, Documentation, and Changelog Updates) — Must be executed last, after Sections 1–2 are complete and verified.
4. **Section 4** (Ecosystem Direction Amendment) — Standalone text amendment to `.archive/20260223-002-ecosystem-direction.md`. May be committed independently.

### Sprint Dependency Notes

Section 1 has internal substeps that must be executed in order: schema changes → dedup module → pipeline integration → rename phase changes → callers. Section 2 is independent of Section 1 and can be parallelized. Section 3 depends on both Sections 1 and 2. Section 4 is a standalone documentation task with no code dependencies.

---

## 1. Provenance-Preserving De-Duplication (Priority: High)

### 1.1. Problem Statement

When the Rename feature is active and multiple files share identical content hashes (and therefore identical `storage_name` values), the current behavior is:

1. The first file encountered is renamed to its `storage_name` (e.g., `slippers.gif` → `yB4ADC74442D00EE0953105C01D42B72B.gif`).
2. Subsequent files with the same hash that reside in the *same directory* are **skipped** — they remain on disk with their original names.
3. Files with the same hash in *different directories* are each renamed independently — producing multiple identical copies under the same `storage_name` in separate locations.
4. A `WARNING`-level log is emitted only for same-directory collisions: `Rename SKIPPED (collision): {original_name} → {storage_name} (target already exists)`.

This produces two problems:

- **Same-directory duplicates** remain on disk alongside the canonical renamed file. Users must manually delete them.
- **Cross-directory duplicates** each get renamed to the same `storage_name` in their respective directories, leaving multiple identical copies on disk. The indexer has no awareness that these represent the same content.

In both cases, the metadata sidecars of the duplicate files are disconnected from the canonical copy. If the user deletes the duplicates manually, the identity metadata (original filenames, timestamps, paths, attached sidecar metadata entries) captured in those sidecars is permanently lost.

### 1.2. Desired Behavior

When Rename is active, the indexer performs session-scoped de-duplication with full provenance retention:

1. **First encounter:** The first file with a given content hash is designated the **canonical** copy. It is renamed to its `storage_name` normally. Its sidecar is written normally.
2. **Subsequent encounters (same hash, any directory):** The file is identified as a **duplicate**. Its complete `IndexEntry` — including its original name, timestamps, filesystem location, and all metadata entries — is absorbed into the canonical entry's new `duplicates` array. The duplicate file is then deleted from disk. Its standalone sidecar is not written (or, if already written, is deleted). One copy of the bytes survives; all identity metadata survives.

**Post-deduplication filesystem (same-directory scenario):**

```
images/
├── yB4ADC74442D00EE0953105C01D42B72B.gif              ← renamed from slippers.gif (canonical)
├── yB4ADC74442D00EE0953105C01D42B72B.gif_meta2.json   ← contains duplicates[] with slippers_01 and slippers_02 provenance
```

The files `slippers_01.gif` and `slippers_02.gif` have been deleted. Their identity metadata is preserved in the canonical entry's `duplicates` array within the sidecar.

**Post-deduplication filesystem (cross-directory scenario):**

```
photos/
├── vacation/
│   ├── yA1B2C3D4.jpg              ← canonical (renamed from beach.jpg)
│   └── yA1B2C3D4.jpg_meta2.json   ← contains duplicates[] with backup/beach_copy.jpg provenance
├── backup/
│   └── (beach_copy.jpg deleted — was byte-identical to vacation/beach.jpg)
```

### 1.3. Design Decisions

**A. Activation gate.** De-duplication activates **only** when Rename is active (`--rename` flag or GUI Rename checkbox). Rename is the prerequisite because:

- Content-addressed rename is what produces `storage_name` collisions in the first place.
- Without rename, files keep their original names and no collision occurs.
- Rename already implies `--inplace` output, which ensures sidecar data is always captured.
- De-duplication without rename (deleting files that happen to have the same hash but keeping original names) would be unexpected and dangerous.

No additional opt-in flag is required. When Rename is active, de-duplication is the default behavior. This is a refinement of the existing collision handling, not a new mode.

**B. Session scope.** De-duplication operates within the scope of a single indexer runtime (a single CLI invocation, a single GUI run, or a single API call). The dedup registry is populated as the entry tree is scanned and is discarded when the process exits. Cross-runtime de-duplication (detecting that file A indexed today is identical to file B indexed last month) is the responsibility of `shruggie-catalog`. See §1.12 for the reuse design that bridges these two scopes.

**C. Canonical selection.** The first file encountered during tree traversal with a given content hash becomes the canonical copy. "First encountered" follows the existing traversal order: depth-first within each directory, sorted by `os.scandir()` enumeration order. This is deterministic for a given filesystem state but not guaranteed across platforms. The canonical designation has no semantic significance beyond "this is the copy that survives on disk" — all copies' identity metadata is preserved equally.

**D. Dry-run interaction.** When `--dry-run` is active, de-duplication is previewed but not executed. The entry tree is scanned and duplicates are identified, but:

- No files are deleted.
- No sidecars are suppressed.
- The `duplicates` array IS populated in the output (so the user can see what would be merged).
- Log messages indicate what *would* happen: `Dry run — would deduplicate: {name} at {relative_path} (duplicate of {canonical_storage_name})`.

**E. No opt-out flag in this batch.** Since de-duplication is the natural completion of content-addressed rename, an opt-out flag would re-introduce the current "leave duplicates on disk" behavior. If user feedback later indicates a need for a `--no-dedup` flag, it can be added in a future batch. For now, the skip-and-warn codepath is fully replaced.

**F. Ecosystem boundary compliance.** The ecosystem direction document (`.archive/20260223-002-ecosystem-direction.md`) states that all destructive operations require explicit opt-in. Rename is the explicit opt-in: the `--rename` flag (or GUI checkbox) is a deliberate user action that signals intent to modify the filesystem. De-duplication is a natural consequence of that intent — renaming files to their content hash makes byte-identical files structurally redundant. Deleting the redundant copies while preserving their identity metadata is the completion of the user's stated goal, not an additional destructive action.

### 1.4. Schema Changes

#### 1.4.A. New top-level field: `duplicates`

A new optional field is added to the `IndexEntry` root object:

| Property | Type | Required | Description |
|----------|------|----------|-------------|
| `duplicates` | `array` of `IndexEntry` | No | Complete `IndexEntry` objects for files that were de-duplicated against this entry during rename. Each element preserves the full identity, filesystem location, timestamps, and metadata of a removed duplicate. Absent (not `null`) when no duplicates were found. |

**Semantics:**

- Each element in `duplicates` is a structurally complete `IndexEntry` — the exact object that would have been written to a standalone sidecar if the file had not been deduplicated.
- The `duplicates` array is populated only on the **canonical** entry (the surviving copy). Duplicate entries that are absorbed do not themselves have a `duplicates` field.
- The array follows the conditional-inclusion convention established by `session_id` and `indexed_at`: present when non-empty, absent when empty. The `to_dict()` serializer omits the key entirely when the list is `None` or empty.
- Within the `duplicates` array, each entry's `items` field is always `null` (duplicates are always files, never directories).
- The `duplicates` field is NOT in the `required` array of the JSON schema.

**Ordering:** In `to_dict()` output and serialized JSON, `duplicates` appears after `metadata` and before `session_id`/`indexed_at`. The updated canonical key order is:

```
schema_version, id, id_algorithm, type, name, extension, mime_type,
size, hashes, file_system, timestamps, attributes, items, metadata,
duplicates, session_id, indexed_at
```

#### 1.4.B. JSON Schema update (`shruggie-indexer-v2.schema.json`)

Add the following property to the root `properties` object in both the canonical hosted schema and the local repository copy:

```json
"duplicates": {
  "description": "Complete IndexEntry objects for files that were de-duplicated against this entry during a rename operation. Each element preserves the full identity metadata of a removed duplicate file. Absent when no duplicates exist for this entry.",
  "type": "array",
  "items": { "$ref": "#" }
}
```

No change to the `required` array. The existing `"additionalProperties": false` constraint means this property MUST be added to the schema before the implementation emits it — otherwise, schema validation will reject output containing `duplicates`.

#### 1.4.C. Python dataclass update (`models/schema.py`)

Add the field to the `IndexEntry` dataclass:

```python
duplicates: list[IndexEntry] | None = None
"""Complete IndexEntry objects for files de-duplicated against this entry."""
```

Position: after `metadata`, before `mime_type`. (The dataclass field order does not affect JSON output order — `to_dict()` controls that.)

#### 1.4.D. Serializer updates (`core/serializer.py`)

1. Add `"duplicates"` to `_TOP_LEVEL_KEY_ORDER` after `"metadata"`.
2. Update `IndexEntry.to_dict()` to conditionally include `duplicates`:

```python
# After the metadata block, before session_id:
if self.duplicates:
    d["duplicates"] = [dup.to_dict() for dup in self.duplicates]
```

This follows the same conditional-inclusion pattern as `session_id` and `indexed_at`: omit the key entirely when there's nothing to report.

#### 1.4.E. Local schema example update

The existing example file at `docs/schema/examples/flashplayer.exe_meta2.json` does not need modification (it represents a non-deduplicated file — `duplicates` is simply absent). However, a **new** example file should be created to demonstrate the `duplicates` field:

**New file:** `docs/schema/examples/deduplicated_meta2.json`

This example should show a canonical entry with one duplicate absorbed, including realistic values for all fields. The implementing agent should construct this from the existing flashplayer example by creating a hypothetical second copy with different name, path, and timestamps but identical content hashes.

> **⚠️ HUMAN ACTION REQUIRED:** After this sprint is implemented and merged, the canonical JSON Schema at `https://schemas.shruggie.tech/data/shruggie-indexer-v2.schema.json` must be updated to include the new `duplicates` property. The local copy in the repository will be updated by the implementing agent, but the hosted version requires manual deployment.

### 1.5. Dedup Module Architecture (`core/dedup.py`)

A new module `src/shruggie_indexer/core/dedup.py` encapsulates all de-duplication logic. This module is designed for standalone importability by downstream projects (specifically `shruggie-catalog`) — it operates on `IndexEntry` objects and has no dependencies on CLI, GUI, or filesystem I/O.

#### 1.5.A. `DedupRegistry` class

```python
class DedupRegistry:
    """Session-scoped registry for content-addressed de-duplication.

    Tracks which content hashes have been seen and which IndexEntry is
    the canonical representative for each hash. Designed for single-session
    use within the indexer and for cross-session reuse by shruggie-catalog.

    The registry key is the ``storage_name`` (which encodes both the content
    hash and the file extension). This means two files with identical bytes
    but different extensions (e.g., ``photo.jpg`` and ``photo.jpeg``) are
    treated as distinct — they produce different ``storage_name`` values
    and are not considered duplicates. This is correct: content-addressed
    identity in the ShruggieTech ecosystem includes the extension as part
    of the storage key.
    """

    def __init__(self) -> None: ...

    def check(self, entry: IndexEntry) -> DedupResult: ...

    def merge(self, canonical: IndexEntry, duplicate: IndexEntry) -> None: ...

    @property
    def stats(self) -> DedupStats: ...
```

#### 1.5.B. `DedupResult` dataclass

```python
@dataclass
class DedupResult:
    """Result of checking an entry against the dedup registry."""
    is_duplicate: bool
    canonical_entry: IndexEntry | None  # The canonical entry if this is a duplicate; None if this is canonical.
```

#### 1.5.C. `DedupStats` dataclass

```python
@dataclass
class DedupStats:
    """Summary statistics for a dedup pass."""
    total_files_scanned: int
    unique_files: int
    duplicates_found: int
    bytes_reclaimed: int  # Sum of duplicate file sizes (entry.size.bytes)
```

#### 1.5.D. `scan_tree()` function

```python
def scan_tree(root_entry: IndexEntry, registry: DedupRegistry) -> list[DedupAction]:
    """Walk an IndexEntry tree and identify all duplicates.

    Returns a list of DedupAction objects describing what needs to happen.
    Does NOT mutate entries or touch the filesystem — that is the caller's
    responsibility.

    This function is the primary entry point for both indexer (single-session)
    and catalog (cross-session) use cases. The caller controls the registry
    lifetime: the indexer creates a fresh registry per run; the catalog
    maintains a persistent registry across runs.

    Args:
        root_entry: The root of the IndexEntry tree to scan.
        registry: The dedup registry to populate/query.

    Returns:
        A list of DedupAction objects, one per duplicate found.
    """
```

#### 1.5.E. `DedupAction` dataclass

```python
@dataclass
class DedupAction:
    """A pending de-duplication action identified by scan_tree()."""
    duplicate_entry: IndexEntry
    canonical_entry: IndexEntry
    duplicate_relative_path: str  # file_system.relative of the duplicate
    canonical_storage_name: str   # storage_name of the canonical entry
```

#### 1.5.F. `apply_dedup()` function

```python
def apply_dedup(actions: list[DedupAction]) -> None:
    """Apply de-duplication actions to the entry tree.

    For each action, merges the duplicate's IndexEntry into the canonical
    entry's ``duplicates`` list. This mutates the canonical entries in place.

    Does NOT touch the filesystem. File deletion and sidecar cleanup are
    handled by the caller (the rename phase in the CLI/GUI pipeline).
    """
```

**Design rationale for the scan/apply split:** Separating identification from mutation allows:

- Dry-run mode to call `scan_tree()` + populate `duplicates` in the output without calling the filesystem deletion logic.
- Catalog to call `scan_tree()` with a persistent registry, inspect results, and apply selectively.
- Testing to verify detection logic independently of filesystem side effects.

### 1.6. Pipeline Integration

The de-duplication pass inserts into the existing processing pipeline as a new phase between entry tree construction and output writing.

**Current pipeline (without dedup):**

```
1. Build entry tree          → index_path() / build_directory_entry()
2. Write in-place sidecars   → _write_inplace_tree()
3. Write aggregate output    → write_output() (stdout + outfile)
4. Rename files              → _rename_tree()
5. MetaMergeDelete cleanup   → delete_queue processing
```

**Revised pipeline (with dedup):**

```
1. Build entry tree          → index_path() / build_directory_entry()
2. ** Dedup scan **          → scan_tree() — identify duplicates     [NEW]
3. ** Dedup apply **         → apply_dedup() — merge into canonical  [NEW]
4. Write in-place sidecars   → _write_inplace_tree() — skip duplicates
5. Write aggregate output    → write_output() — includes duplicates[]
6. Rename + dedup cleanup    → _rename_tree() — rename canonical, delete duplicates
7. MetaMergeDelete cleanup   → delete_queue processing
```

**Key sequencing insight:** By running the dedup pass *before* output writing:

- The aggregate output (stdout, outfile) includes the `duplicates` data — the user sees the complete provenance record.
- In-place sidecars for duplicate files are never written — no orphaned sidecars to clean up.
- The canonical entry's in-place sidecar includes the `duplicates` data when written.
- The rename phase only needs to handle filesystem operations (rename canonical, delete duplicates), not data merging.

### 1.7. Dedup-Aware Sidecar Writing

The `_write_inplace_tree()` function (in both `cli/main.py` and `gui/app.py`) must skip entries that have been consumed as duplicates.

**Approach:** After `apply_dedup()` runs, duplicate entries are removed from their parent's `items` array (they are no longer standalone entries — their data lives in the canonical entry's `duplicates` list). Therefore, `_write_inplace_tree()` naturally skips them because they no longer appear in the tree. No modification to `_write_inplace_tree()` itself is required for the skip behavior.

**However**, the removal of duplicate entries from `items` must be handled carefully:

- `apply_dedup()` removes duplicate entries from their parent directory's `items` list.
- This means the `items` array of the parent directory accurately reflects the post-dedup filesystem state: only the files that still exist on disk are listed.
- The duplicate's provenance is accessible via the canonical entry's `duplicates` array, which may be in a completely different directory's subtree.

### 1.8. Dedup-Aware Rename Phase

The `_rename_tree()` function (in both `cli/main.py` and `gui/app.py`) requires modification to handle the dedup outcome.

**Current behavior in the collision branch of `rename_item()`:**

```python
# Different inode = collision — skip and warn
logger.warning(
    "Rename SKIPPED (collision): %s → %s (target already exists)",
    original_path.name, storage_name,
)
return original_path
```

**After dedup integration, this branch should never execute for same-directory collisions** — the dedup pass has already removed the duplicate from `items`, so `_rename_tree()` never visits it. The canonical file is the only one left, and it gets renamed normally.

For safety, the collision branch should be retained as a defensive guard but updated to log at `ERROR` level (since it indicates the dedup pass missed something):

```python
# Different inode = collision — should not happen after dedup pass
logger.error(
    "Unexpected rename collision after dedup: %s → %s (target already exists). "
    "This indicates a bug in the dedup pipeline.",
    original_path.name, storage_name,
)
return original_path
```

**File deletion for cross-directory duplicates** is handled by a new helper called from the main pipeline after the rename phase. The dedup scan produces a list of `DedupAction` objects, each of which includes the `duplicate_relative_path`. The pipeline iterates this list and deletes each duplicate file (and its sidecar, if one was written before the dedup pass — which shouldn't happen with the revised pipeline, but as a safety net):

```python
def cleanup_duplicate_files(
    actions: list[DedupAction],
    root_path: Path,
    *,
    dry_run: bool = False,
) -> None:
    """Delete duplicate files from disk after dedup merge.

    Called after the rename phase. Each action's duplicate_relative_path
    identifies a file that was merged into a canonical entry's duplicates
    array and should no longer exist on disk.
    """
```

### 1.9. Log Messages

| Level | Condition | Message |
|-------|-----------|---------|
| `INFO` | Duplicate identified during scan | `Duplicate found: {name} at {relative_path} (identical to {canonical_storage_name})` |
| `INFO` | Duplicate file deleted | `Duplicate removed: {name} at {relative_path} (provenance preserved in {canonical_storage_name})` |
| `DEBUG` | Orphaned sidecar deleted | `Orphaned sidecar deleted: {sidecar_path}` |
| `INFO` | Dry-run preview | `Dry run — would deduplicate: {name} at {relative_path} (duplicate of {canonical_storage_name})` |
| `INFO` | Dedup summary at end of run | `De-duplication: {duplicates_found} duplicate(s) found across {unique_files} unique content hashes. {bytes_text} reclaimed.` |
| `ERROR` | Unexpected collision after dedup | `Unexpected rename collision after dedup: {original_name} → {storage_name} (target already exists). This indicates a bug in the dedup pipeline.` |
| `WARNING` | Duplicate file deletion failed | `Failed to delete duplicate file: {path}: {exception}` |

### 1.10. Return Value Contract Update

The `rename_item()` function return type does **not** change. The dedup pass removes duplicates from the tree before rename runs, so `rename_item()` is only ever called for canonical files. The collision branch becomes a defensive error path, not a normal control flow.

| Outcome | Return value |
|---------|-------------|
| Renamed successfully | New `Path` (target path) |
| Dry-run preview | Would-be `Path` (target path) |
| No-op (same inode, already renamed) | Existing `Path` (target path) |
| Unexpected collision (defensive) | `original_path` (unchanged, logged as ERROR) |

### 1.11. Affected Files

| File | Nature of change |
|------|------------------|
| `docs/schema/shruggie-indexer-v2.schema.json` | Add `duplicates` property to root object. |
| `src/shruggie_indexer/models/schema.py` | Add `duplicates: list[IndexEntry] or None = None` to `IndexEntry`. Update `to_dict()`. |
| `src/shruggie_indexer/core/serializer.py` | Add `"duplicates"` to `_TOP_LEVEL_KEY_ORDER`. |
| `src/shruggie_indexer/core/dedup.py` | **New file.** `DedupRegistry`, `DedupResult`, `DedupStats`, `DedupAction`, `scan_tree()`, `apply_dedup()`, `cleanup_duplicate_files()`. |
| `src/shruggie_indexer/core/__init__.py` | Re-export dedup public API if appropriate. |
| `src/shruggie_indexer/cli/main.py` | Insert dedup scan/apply between entry build and output write. Call `cleanup_duplicate_files()` after rename. |
| `src/shruggie_indexer/gui/app.py` | Same pipeline insertion as CLI. |
| `src/shruggie_indexer/core/rename.py` | Update collision branch to `ERROR`-level defensive guard. |
| `docs/schema/examples/deduplicated_meta2.json` | **New file.** Example output with `duplicates` array. |
| `tests/unit/test_dedup.py` | **New file.** Unit tests for `DedupRegistry`, `scan_tree()`, `apply_dedup()`. |
| `tests/integration/test_dedup_rename.py` | **New file.** Integration tests: same-dir dedup, cross-dir dedup, dry-run, provenance preservation. |

### 1.12. Downstream Reuse Design (shruggie-catalog)

The dedup module (`core/dedup.py`) is designed for direct import by `shruggie-catalog`:

```python
from shruggie_indexer.core.dedup import DedupRegistry, scan_tree, apply_dedup
```

**Indexer usage (single-session):**

```python
registry = DedupRegistry()
actions = scan_tree(root_entry, registry)
apply_dedup(actions)
# registry is discarded when the process exits
```

**Catalog usage (cross-session):**

```python
# Catalog maintains a persistent registry backed by its database
registry = DedupRegistry()

# Load existing content hashes from the catalog database
for existing_entry in catalog.get_all_entries():
    registry.register(existing_entry)

# Process a new batch of entries from a fresh indexer run
actions = scan_tree(new_batch_root, registry)
# Catalog inspects actions and applies selectively based on policy
for action in actions:
    if catalog.policy.should_deduplicate(action):
        apply_dedup([action])
        catalog.record_dedup_event(action)
```

The key differential: the indexer's registry lives for one runtime and starts empty. The catalog's registry is pre-populated from the database and persists across runtimes. The scan/apply logic is identical — only the registry lifetime and action filtering differ.

**Module dependency direction:** `shruggie-catalog` imports from `shruggie-indexer`. This is consistent with the ecosystem dependency order defined in the direction document: `indexer ← catalog`.

### 1.13. Acceptance Criteria

1. When Rename is active and two or more files share identical content hashes (identical `storage_name`), the first file is designated canonical and renamed normally; all subsequent duplicates are deleted from disk.
2. Each deleted duplicate's complete `IndexEntry` (including name, timestamps, file_system, and all metadata entries) is preserved in the canonical entry's `duplicates` array.
3. The canonical entry's in-place sidecar file contains the `duplicates` array.
4. The aggregate output (stdout, outfile) contains the `duplicates` array.
5. Cross-directory de-duplication works: a file in `dir_a/` that is byte-identical to a file in `dir_b/` is detected and deduplicated.
6. The `duplicates` field is absent from entries with no duplicates (not `null`, not empty array — absent).
7. Dry-run mode identifies and reports duplicates, populates `duplicates` in the output, but does not delete any files.
8. The dedup summary log message reports the number of duplicates found and bytes reclaimed.
9. The local JSON schema (`docs/schema/shruggie-indexer-v2.schema.json`) includes the `duplicates` property.
10. A new example file (`docs/schema/examples/deduplicated_meta2.json`) demonstrates the `duplicates` field with realistic data.
11. `DedupRegistry`, `scan_tree()`, and `apply_dedup()` are importable from `shruggie_indexer.core.dedup` for downstream reuse.
12. Unit tests cover: registry population, duplicate detection, canonical selection, merge behavior, stats calculation, empty-tree edge case, single-file edge case.
13. Integration tests cover: same-directory dedup, cross-directory dedup, dry-run output, provenance preservation round-trip (verify all fields survive the merge).
14. No regressions in existing rename tests.
15. The collision branch in `rename_item()` logs at `ERROR` level (defensive guard — should never fire after dedup pass).

---

## 2. Suppress Directory Metadata Output (Priority: Medium)

### 2.1. Problem Statement

When the indexer processes a directory target, it produces two categories of output files:

1. **Per-file sidecars** (`{filename}_meta2.json`) — Individual metadata records for each file in the tree.
2. **Directory metadata files** (`_directorymeta2.json`) — Aggregate records for the directory structure. These include both the top-level aggregate output file and in-place directory sidecars for each subdirectory.

In practice, users consistently delete the `_directorymeta2.json` files after each run. The per-file sidecars are the desired persistent output — they serve as rename reversal manifests and carry the metadata needed for downstream catalog operations. The directory-level files are informational at best and clutter at worst.

### 2.2. Desired Behavior

A new configuration option allows users to suppress directory metadata output while leaving per-file sidecars unaffected.

### 2.3. Design Principle: Stdout Orthogonality

The `--no-dir-meta` flag controls **what file artifacts are written to disk**. It does **not** affect stdout output.

This follows the universal Unix CLI principle: flags that control *what content to produce* are orthogonal to flags that control *where the content goes*. The three output destinations (`--stdout`, `--outfile`, `--inplace`) are independent routing channels. The `--no-dir-meta` flag modifies the *content* that flows through the file-based channels (`--outfile` and `--inplace`) but does not suppress or alter the stdout channel.

**Rationale:** A user who runs `shruggie-indexer /path/to/dir | jq .items` expects the complete directory entry tree on stdout regardless of whether directory sidecar files are written to disk. Suppressing stdout based on a file-output preference would break pipeline composability.

**Concrete behavior matrix:**

| Flag combination | stdout | outfile | in-place file sidecars | in-place dir sidecars |
|------------------|--------|---------|----------------------|---------------------|
| `--inplace` (default) | OFF | — | Written | Written |
| `--inplace --no-dir-meta` | OFF | — | Written | **Suppressed** |
| `--inplace --no-dir-meta --stdout` | ON (full tree) | — | Written | **Suppressed** |
| `--outfile out.json --no-dir-meta` | OFF | Written (full tree) | — | — |
| (no flags, default stdout) `--no-dir-meta` | ON (full tree) | — | — | — |

The `--outfile` aggregate file always contains the full tree structure (including directory entries with their `items` arrays) because the aggregate output is a single JSON document representing the complete index. The `--no-dir-meta` flag does not modify the aggregate JSON structure — it only suppresses the individual `_directorymeta2.json` sidecar files written to disk during in-place output.

### 2.4. New Configuration Field

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `write_directory_meta` | `bool` | `True` | When `False`, suppresses writing `_directorymeta2.json` sidecar files (both the root aggregate file and in-place directory sidecars). Per-file `_meta2.json` sidecars are unaffected. Stdout and `--outfile` aggregate output are unaffected. |

**Config path:** `IndexerConfig.write_directory_meta`
**TOML path:** `[output] write_directory_meta = false`

### 2.5. CLI Flag

```python
@click.option("--dir-meta/--no-dir-meta", default=None)
```

Tri-state default (`None`) triggers the config defaulting logic: if not explicitly set, the value comes from the TOML config file or falls back to `True`.

The flag controls only file writes:

- When `--no-dir-meta` is active and `--inplace` is active:
  - Per-file `_meta2.json` sidecars: **written** (unaffected).
  - In-place `_directorymeta2.json` for subdirectories: **suppressed**.
  - Root-level aggregate `_directorymeta2.json` (the file written by the `output_file` path for directory targets): **suppressed**.
- When `--no-dir-meta` is active and `--outfile` is active:
  - The `--outfile` aggregate JSON is written normally (full tree). This is a single file at a user-specified path, not a `_directorymeta2.json` file.
- When `--no-dir-meta` is active and stdout is active:
  - Stdout output is written normally (full tree).

**Note on `output_file` for directory targets:** When no `--outfile` is specified and the target is a directory, the default aggregate output file is `{target_dir}_directorymeta2.json` written alongside the target directory. This file IS subject to `--no-dir-meta` suppression because it is a `_directorymeta2.json` file. When the user provides an explicit `--outfile` path (e.g., `--outfile /tmp/index.json`), that file is NOT subject to suppression — the user explicitly asked for it at a specific location.

### 2.6. GUI Implementation

**A. Checkbox:** "Write directory summary files"

- **Location:** Operations page → Output card, after the Mode dropdown and before the output path display.
- **Default:** Checked (enabled).
- **Variable:** `_write_dir_meta_var = ctk.BooleanVar(value=True)`
- **Config wiring:** `overrides["write_directory_meta"] = self._write_dir_meta_var.get()`
- **Session persistence:** `write_directory_meta` boolean field in the session state.

**B. Output Mode constraint — Single file mode:**

When the target is a directory and `write_directory_meta` is `False`, **Single file mode** must be disabled. Single file mode for a directory target writes one artifact: the `_directorymeta2.json` aggregate file. Suppressing that file produces zero output — a contradiction.

| Condition | Single file | Multi-file | View only |
|-----------|:-----------:|:----------:|:---------:|
| Dir target, dir meta ON | ✓ | ✓ (default) | ✓ |
| Dir target, dir meta OFF | ✗ disabled | ✓ (forced default) | ✓ |
| File target (checkbox irrelevant) | ✓ (default) | ✗ | ✓ |

Info-label when Single file is blocked: *"Single file mode requires directory summary output. Enable 'Write directory summary files' or use Multi-file mode."*

**C. MetaMergeDelete safety constraint:**

MetaMergeDelete requires at least one persistent output mechanism (`output_file` or `output_inplace`). When `write_directory_meta` is `False`:

- `output_file` for directory targets is suppressed (the default `_directorymeta2.json`).
- `output_inplace` for directories is suppressed (but per-file sidecars are still written).

Since per-file sidecars (`output_inplace` for files) ARE still written when `--no-dir-meta` is active, the MetaMergeDelete safety invariant is satisfied — merged sidecar data is captured in the per-file sidecars. The constraint from Batch 001 ("force Multi-file mode") is therefore the correct resolution: Multi-file mode ensures `output_inplace` is active for files.

When MetaMergeDelete is active AND `write_directory_meta` is `False`:

- Force output mode to Multi-file (if not already).
- Info-label: *"Multi-file mode is required when directory output is suppressed with Meta Merge Delete. Per-file sidecars preserve merged sidecar data."*

**D. File target behavior:**

When the target is a single file, the `write_directory_meta` checkbox has no effect (there are no directory-level files to suppress). The checkbox should be disabled with fine-print: *"Directory output is only applicable for directory targets."*

**E. Output path display:**

When the checkbox is unchecked and the target is a directory:

- If output mode is Multi-file: display *"(per-file sidecars only — directory summaries suppressed)"*.
- If output mode is View only: display the standard View only text.

### 2.7. Implementation Details

**A. `config/types.py` — Add field:**

```python
write_directory_meta: bool = True
```

**B. `config/loader.py` — Wire through:**

Add `"write_directory_meta"` to `scalar_keys` in the configuration loader.

**C. `cli/main.py` — Gate in-place directory writes:**

Modify `_write_inplace_tree()` to accept the config (or the `write_directory_meta` flag) as a parameter:

```python
def _write_inplace_tree(
    entry: Any,
    root_path: Path,
    write_fn: Any,
    *,
    _is_root: bool = True,
    write_directory_meta: bool = True,  # NEW
) -> None:
    if entry.type == "file":
        item_path = root_path.parent / entry.file_system.relative
        write_fn(entry, item_path, "file")
    elif entry.type == "directory":
        if not _is_root and write_directory_meta:  # MODIFIED
            dir_path = root_path.parent / entry.file_system.relative
            write_fn(entry, dir_path, "directory")
        if entry.items:
            for child in entry.items:
                _write_inplace_tree(
                    child, root_path, write_fn,
                    _is_root=False,
                    write_directory_meta=write_directory_meta,  # THREAD THROUGH
                )
```

**D. `cli/main.py` — Gate aggregate directory output:**

The aggregate output (`write_output()`) writes the full entry tree to stdout and/or an outfile. When `--no-dir-meta` is active and the target is a directory, the default `output_file` (which would be `{target}_directorymeta2.json`) should be suppressed:

```python
# Before calling write_output():
if not config.write_directory_meta and entry.type == "directory" and config.output_file is not None:
    # Check if output_file is the auto-generated _directorymeta2.json path
    # Only suppress auto-generated paths, not user-specified --outfile paths
    if str(config.output_file).endswith("_directorymeta2.json"):
        logger.info("Directory aggregate output suppressed (--no-dir-meta).")
        # Set output_file to None for this write call, preserving stdout behavior
        config_for_write = replace(config, output_file=None)
    else:
        config_for_write = config
else:
    config_for_write = config

write_output(entry, config_for_write)
```

**Important:** This suppression ONLY applies to the auto-generated `_directorymeta2.json` aggregate file. If the user explicitly passes `--outfile /path/to/custom.json`, that file is always written — the user asked for it specifically.

**E. `gui/app.py` — Same modifications as CLI:**

- Thread `write_directory_meta` through `_write_inplace_tree()`.
- Gate the aggregate output write using the same auto-generated path check.
- Add the checkbox, constraints, and session persistence as described in §2.6.

### 2.8. Affected Files

| File | Nature of change |
|------|------------------|
| `src/shruggie_indexer/config/types.py` | Add `write_directory_meta: bool = True` to `IndexerConfig`. |
| `src/shruggie_indexer/config/loader.py` | Add `"write_directory_meta"` to scalar keys. |
| `src/shruggie_indexer/cli/main.py` | Add `--dir-meta/--no-dir-meta` flag. Thread through `_write_inplace_tree()`. Gate aggregate output. |
| `src/shruggie_indexer/gui/app.py` | Add checkbox, constraints, session persistence, output path display logic. Thread through `_write_inplace_tree()`. Gate aggregate output. |
| `tests/unit/test_serializer.py` | Add tests for `write_directory_meta=False` suppression of in-place directory sidecars. |
| `tests/integration/test_output_modes.py` | Add tests verifying: directory sidecar suppression, stdout unaffected, outfile unaffected, auto-generated path suppression vs. explicit path preservation. |

### 2.9. Spec References

| Reference | Section |
|-----------|---------|
| Output routing model | `shruggie-indexer-spec.md` §6.9 |
| Output scenarios | `shruggie-indexer-spec.md` §8.9 |
| CLI output flags | `shruggie-indexer-spec.md` §8.3 |
| GUI output controls | `shruggie-indexer-spec.md` §10.3 (Output controls) |
| MetaMergeDelete safety | `shruggie-indexer-spec.md` §7.1 (Validation rules) |
| Configuration architecture | `shruggie-indexer-spec.md` §7.1 |

### 2.10. Acceptance Criteria

1. A new `--dir-meta/--no-dir-meta` CLI flag is available, defaulting to `--dir-meta` (enabled).
2. When `--no-dir-meta` is passed with a directory target and `--inplace` is active, no `_directorymeta2.json` files are written (neither the root aggregate nor in-place subdirectory sidecars).
3. Per-file `_meta2.json` sidecars are unaffected by this flag.
4. **Stdout is unaffected by this flag.** When stdout is active (by default or via `--stdout`), the full directory entry tree is written to stdout regardless of `--no-dir-meta`.
5. An explicit `--outfile /path/to/custom.json` is unaffected by this flag — the file is always written.
6. The auto-generated `_directorymeta2.json` aggregate file IS suppressed by this flag.
7. When `--no-dir-meta` is passed with a single-file target, behavior is unchanged (the flag is silently ignored — there are no directory-level files to suppress).
8. The GUI exposes a "Write directory summary files" checkbox in the Output card.
9. When the checkbox is unchecked and the target is a directory, Single file output mode is disabled with an explanatory info-label.
10. When MetaMergeDelete is active AND the checkbox is unchecked, output mode is forced to Multi-file with an explanatory info-label.
11. Checkbox state persists across GUI sessions.
12. No regressions in existing output mode tests.

---

## 3. Specification, Documentation, and Changelog Updates (Priority: Required — Execute Last)

### 3.1. Specification Updates

The following sections of `shruggie-indexer-spec.md` must be updated to reflect the changes implemented in Sections 1–2. All updates must use the amendment callout convention: `> **Updated 2026-03-01:**`.

| Spec section | Triggering section | Nature of update |
|--------------|--------------------|------------------|
| §5.3 — Top-level fields | Section 1 | Add `duplicates` to the field inventory table. Add row with type `array[IndexEntry]`, Required=No, Section=§5.11 (new). |
| §5 (new §5.11) — Duplicates field | Section 1 | **New subsection.** Document the `duplicates` field: semantics, conditional inclusion, relationship to rename, schema validation. |
| §6.10 — Collision detection | Section 1 | Rewrite collision behavior: describe the dedup pass, session-scoped registry, canonical selection, provenance preservation. Replace the skip-and-warn narrative with the new dedup-and-merge narrative. Update log messages. Document the defensive ERROR-level collision guard. |
| §6.10 — Rename implies dedup | Section 1 | **New subsection under §6.10.** Document that Rename activates de-duplication automatically. Describe the pipeline integration (scan → apply → write → rename → cleanup). |
| §6.9 — Output routing | Section 2 | Document the `write_directory_meta` config field and its effect on in-place directory sidecar writes and auto-generated aggregate file writes. Explicitly document that stdout and explicit `--outfile` paths are unaffected (stdout orthogonality). |
| §7.1 — Configuration architecture | Sections 1+2 | Add `write_directory_meta` to the `IndexerConfig` dataclass listing. Document the dedup pipeline phase in the processing overview if one exists. |
| §7.1 — Validation rules | Section 2 | Add the MetaMergeDelete + `write_directory_meta=False` constraint (forces Multi-file in GUI; CLI relies on user to specify `--inplace`). |
| §7.2 — Default configuration | Section 2 | Add `write_directory_meta: True` to the compiled defaults. |
| §8.3 — Output flags | Section 2 | Document the `--dir-meta/--no-dir-meta` flag pair. Explicitly state stdout orthogonality. |
| §8.9 — Output scenarios | Section 2 | Add notes to relevant scenarios indicating `--no-dir-meta` suppresses in-place directory sidecars but does not affect stdout or explicit outfile. |
| §9 — Python API | Section 1 | Document `DedupRegistry`, `scan_tree()`, `apply_dedup()` as public API for downstream consumers. |
| §10.3 — GUI output controls | Section 2 | Document the "Write directory summary files" checkbox, position, tooltip, constraint interactions (Single file mode, MetaMergeDelete), and session persistence. |

### 3.2. Documentation Site Updates

| File | Nature of update |
|------|------------------|
| `docs/user-guide/cli.md` | Document `--dir-meta/--no-dir-meta` flag. Add a section on rename de-duplication behavior and provenance preservation. |
| `docs/user-guide/gui.md` | Add the "Write directory summary files" checkbox to the Output Section description. Document de-duplication behavior during rename. Add a note about the `duplicates` field in sidecar output. |
| `docs/user-guide/python-api.md` | Document `write_directory_meta` in the `IndexerConfig` field table. Document the `core.dedup` module's public API (`DedupRegistry`, `scan_tree()`, `apply_dedup()`) for programmatic usage. |
| `docs/schema/index.md` | Add `duplicates` to the top-level field table. Add a subsection documenting the field's semantics and conditional inclusion. Update or add an example showing the `duplicates` field in context. |
| `docs/schema/shruggie-indexer-v2.schema.json` | Add `duplicates` property (as specified in §1.4.B). |
| `docs/schema/examples/deduplicated_meta2.json` | **New file.** Example entry with `duplicates` array. |

### 3.3. Changelog Updates

Add entries under a new `### Added` and `### Changed` section for the current date:

**Added:**

- **Core: Provenance-preserving de-duplication** — When Rename is active, files sharing identical content hashes are deduplicated: the first file becomes the canonical copy (renamed to `storage_name`); all subsequent duplicates are deleted. Each duplicate's complete `IndexEntry` — including original name, timestamps, filesystem location, and all metadata entries — is preserved in the canonical entry's new `duplicates` array. De-duplication is session-scoped and applies across all directories in recursive operations.
- **Schema: `duplicates` field** — New optional top-level field on `IndexEntry`. An array of complete `IndexEntry` objects representing files that were de-duplicated against this entry. Absent when no duplicates exist.
- **Core: `core/dedup` module** — New module providing `DedupRegistry`, `scan_tree()`, and `apply_dedup()` for session-scoped de-duplication. Designed for standalone import by downstream projects (`shruggie-catalog`).
- **CLI: `--dir-meta/--no-dir-meta` flag** — Controls whether directory-level metadata files (`_directorymeta2.json`) are written to disk. Defaults to enabled. Per-file sidecars, stdout output, and explicit `--outfile` paths are unaffected. Follows Unix stdout orthogonality: `--no-dir-meta` suppresses file writes only.
- **GUI: "Write directory summary files" checkbox** — New checkbox in the Output card on the Operations page. When unchecked, directory-level `_directorymeta2.json` files are suppressed. Disables Single file mode for directory targets when unchecked. State persists across sessions.

**Changed:**

- **Core: Rename collision behavior** — Same-directory rename collisions (previously skip-and-warn) are now handled by the de-duplication pipeline. The collision branch in `rename_item()` is retained as a defensive guard at `ERROR` level.
- **Core: Processing pipeline** — Two new phases inserted between entry tree construction and output writing: dedup scan and dedup apply. The rename phase no longer handles duplicate detection — it only processes canonical files.

### 3.4. Update Principles

1. Preserve the spec's existing style, cross-referencing notation (§X.Y), and formatting.
2. Use `> **Updated 2026-03-01:**` amendment callouts for all changes.
3. Verify no §X.Y cross-references are broken after edits.
4. Regenerate the `.html` and `.pdf` spec renderings from the updated `.md` source.

### 3.5. Spec Header Update

- **Date:** Change to `2026-03-01`.
- **Status:** Remains `AMENDED`.

### 3.6. Acceptance Criteria

- Every behavioral change from Sections 1–2 is reflected in the spec.
- No spec section describes behavior that contradicts the implemented code.
- All cross-references remain valid.
- The changelog accurately summarizes both features and all behavioral changes.
- The documentation site pages are consistent with the spec and the implementation.
- The new `duplicates` field is documented in the schema reference, spec, Python API docs, and GUI/CLI user guides.

---

## 4. Ecosystem Direction Amendment (Priority: Low — Standalone)

### 4.1. Purpose

The archived ecosystem direction document (`.archive/20260223-002-ecosystem-direction.md`) defines component boundaries and invariants for the ShruggieTech ecosystem. The de-duplication feature introduced in Section 1 touches on several of these boundaries. An amendment is needed to:

1. Clarify the indexer's expanded role in filesystem mutation (rename + dedup).
2. Document the boundary between indexer-scoped dedup (single session) and catalog-scoped dedup (cross-session).
3. Preserve the invariant that the catalog is the authoritative cross-session dedup authority.

### 4.2. Amendments

The following additions should be inserted into the ecosystem direction document at the indicated locations.

**A. Under `shruggie-indexer` → `Responsibilities`, add:**

> - Perform single-session, content-addressed de-duplication during rename operations. Duplicate files are deleted; their complete identity metadata is preserved in the canonical entry's `duplicates` array. This dedup scope is strictly bounded to a single runtime invocation.

**B. Under `shruggie-indexer` → `Non-responsibilities`, add:**

> - No cross-session de-duplication. The indexer has no knowledge of entries produced by prior invocations. Cross-session dedup — detecting that a file indexed today is identical to one indexed last month — is the catalog's responsibility.

**C. Under `shruggie-indexer` → `Invariants`, amend the existing invariant:**

Current text:
> `IndexEntry` output is the only artifact this tool emits. It does not side-effect storage.

Amended text:
> `IndexEntry` output is the primary artifact this tool emits. When Rename mode is active, the tool also performs filesystem mutations: renaming files to their content-addressed `storage_name` and, as a consequence of rename, deleting byte-identical duplicate files whose identity metadata has been preserved in the canonical entry's `duplicates` array. These mutations are gated behind the explicit `--rename` flag — they never occur in the default mode.

**D. Under `shruggie-catalog` → `Responsibilities`, add:**

> - Perform cross-session de-duplication by maintaining a persistent `DedupRegistry` backed by its database. When new `IndexEntry` records are ingested, the catalog checks them against all previously cataloged entries. The catalog reuses the indexer's `core.dedup` module (`DedupRegistry`, `scan_tree()`, `apply_dedup()`) for this purpose — the detection and merge logic is identical; only the registry lifetime and scope differ.

**E. New section after `Composition Rules`, before `Design Goals`:**

> ## De-Duplication Scope Boundaries
>
> Content-addressed de-duplication operates at two distinct scopes within the ecosystem:
>
> | Scope | Component | Registry lifetime | Detects |
> |-------|-----------|-------------------|---------|
> | Single session | Indexer | One CLI/GUI/API invocation | Duplicates within a single directory tree processed in one run |
> | Cross-session | Catalog | Persistent (database-backed) | Duplicates across all previously cataloged entries, regardless of when or where they were indexed |
>
> The indexer's dedup module (`shruggie_indexer.core.dedup`) provides the shared implementation for both scopes. The indexer creates a fresh `DedupRegistry` per invocation; the catalog pre-populates the registry from its database before processing new entries.
>
> This separation ensures that:
> - The indexer remains standalone and stateless between runs.
> - The catalog is the single authority for cross-session identity resolution.
> - The dedup logic is implemented once and reused, not reimplemented in each component.

### 4.3. Affected Files

| File | Nature of change |
|------|------------------|
| `.archive/20260223-002-ecosystem-direction.md` | Amendments A–E as described above. |

### 4.4. Acceptance Criteria

- All five amendments are applied to the ecosystem direction document.
- The document remains internally consistent (no contradictions between the new text and existing text).
- The indexer's expanded responsibilities are explicitly scoped and gated behind `--rename`.
- The catalog's cross-session dedup role is clearly documented.
- The shared implementation architecture (catalog imports from indexer) is documented.
